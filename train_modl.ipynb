{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models.modl import modl\n",
    "from torch.utils.data import DataLoader\n",
    "from Transforms import (pad, trim_coils, combine_coil, toTensor, permute, \n",
    "                        view_as_real, remove_slice_dim, fft_2d, normalize, addChannels)\n",
    "from Dataset.undersampled_dataset import UndersampledKSpaceDataset\n",
    "from torchvision.transforms import Compose\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    undersampled = [d['undersampled'] for d in data]\n",
    "    sampled = [d['k_space'] for d in data]\n",
    "    ismrmrd_header = [d['ismrmrd_header'] for d in data]\n",
    "    mask = [d['mask'] for d in data]\n",
    "    recon_rss = [d['reconstruction_rss'] for d in data]\n",
    "\n",
    "    undersampled = torch.concat(undersampled, dim=0)\n",
    "    sampled = torch.concat(sampled, dim=0)\n",
    "    mask = torch.concat(mask, dim=0)\n",
    "\n",
    "    data = {\n",
    "        'undersampled': undersampled, \n",
    "        'sampled': sampled,\n",
    "        'ismrmrd_header': ismrmrd_header,\n",
    "        'mask': mask, \n",
    "        'recon': recon_rss,\n",
    "    }\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = Compose(\n",
    "    (\n",
    "        trim_coils(12),\n",
    "        pad((640, 320)), \n",
    "        fft_2d(axes=[2,3]),\n",
    "        combine_coil(),\n",
    "        normalize(),\n",
    "        toTensor(),\n",
    "    )\n",
    ")\n",
    "dataset = UndersampledKSpaceDataset('D:/multicoil_train', transforms=transforms)\n",
    "dataloader = DataLoader(dataset, batch_size=1, collate_fn=collate_fn)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (next(iter(dataloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "cProfile.run('next(iter(dataloader))', 'dataloader.profile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = modl(1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), momentum=0.99, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_function, optimizer, dataloader):\n",
    "    cur_loss = 0\n",
    "    current_index = 0\n",
    "    for data in dataloader:\n",
    "        \n",
    "        sampled = data['sampled']\n",
    "        mask = data['mask']\n",
    "        undersampled = data['undersampled']\n",
    "        for i in range(sampled.shape[0]):\n",
    "            optimizer.zero_grad()\n",
    "            sampled_slice = sampled[[i],...]\n",
    "            mask_slice = mask[[i],...]\n",
    "            undersampled_slice = undersampled[[i],...]\n",
    "\n",
    "            predicted_sampled = model(undersampled_slice, mask_slice, 1)\n",
    "            loss = loss_function(torch.view_as_real(predicted_sampled), torch.view_as_real(sampled_slice))\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            cur_loss += loss.item()\n",
    "            if current_index % 10 == 9:\n",
    "                print(f\"Iteration: {current_index + 1:>d}, Loss: {cur_loss:>7f}\")\n",
    "                cur_loss = 0\n",
    "            current_index += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10, Loss: 2.502711\n",
      "Iteration: 4, Loss: 5.851493\n",
      "Iteration: 14, Loss: 9.766493\n",
      "Iteration: 8, Loss: 8.772163\n",
      "Iteration: 2, Loss: 8.291339\n",
      "Iteration: 12, Loss: 6.630379\n",
      "Iteration: 6, Loss: 5.387787\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train(model, loss_fn, optimizer, dataloader)\n",
      "Cell \u001b[1;32mIn[15], line 18\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, loss_function, optimizer, dataloader)\u001b[0m\n\u001b[0;32m     15\u001b[0m predicted_sampled \u001b[39m=\u001b[39m model(undersampled_slice, mask_slice, \u001b[39m1\u001b[39m)\n\u001b[0;32m     16\u001b[0m loss \u001b[39m=\u001b[39m loss_function(torch\u001b[39m.\u001b[39mview_as_real(predicted_sampled), torch\u001b[39m.\u001b[39mview_as_real(sampled_slice))\n\u001b[1;32m---> 18\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     19\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     20\u001b[0m cur_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\brend\\miniconda3\\envs\\mr_recon\\lib\\site-packages\\torch\\_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    487\u001b[0m     )\n\u001b[1;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    490\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\brend\\miniconda3\\envs\\mr_recon\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, loss_fn, optimizer, dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mr_recon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4aa5cd992e3bf05f8082836cec6e5d6dda434b6a9281bd71fe0f777b4953a59d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
